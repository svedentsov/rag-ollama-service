# ===================================================================
# Основные настройки сервера
# ===================================================================
server:
  port: 8080 # Порт, на котором будет работать приложение
  error:
    # Включать stacktrace в ответ об ошибке только при наличии параметра ?trace=true.
    # Безопасная настройка для production.
    include-stacktrace: on_param

spring:
  application:
    name: rag-ollama-service # Имя приложения, используется в логах и метриках
  lifecycle:
    timeout-per-shutdown-phase: 30s # Таймаут для корректного завершения работы приложения (graceful shutdown)
  mvc:
    async:
      # Таймаут для асинхронных запросов в контроллерах.
      # ВАЖНО: Должен быть немного больше, чем таймаут в Resilience4j (timelimiter),
      # чтобы дать механизму отказоустойчивости сработать первым.
      request-timeout: 130s

  # --- Database & Persistence ---
  datasource:
    # Данные для подключения к PostgreSQL, запущенному в Docker Compose.
    url: jdbc:postgresql://localhost:5432/ragdb
    username: user
    password: password
    driver-class-name: org.postgresql.Driver
  jpa:
    # `validate`: Проверять схему БД на соответствие сущностям при старте.
    # Самый безопасный вариант для production, предотвращающий случайные изменения схемы.
    hibernate:
      ddl-auto: validate
    show-sql: false # !!! PRODUCTION: Установить в `false` для снижения объема логов и повышения производительности.
    properties:
      hibernate:
        format_sql: true # Форматирует SQL для лучшей читаемости в логах.
  flyway:
    enabled: true
    locations: classpath:db/migration # Путь к SQL-миграциям.
  cache:
    cache-names:
      - vector_search_results # Кэш для результатов RAG-поиска.
      - token_counts # Кэш для подсчета токенов.
    caffeine:
      # Настройки кэша: макс. 500 записей, время жизни записи 10 минут.
      spec: maximumSize=500,expireAfterWrite=10m

  # ===================================================================
  # AI & RAG Pipeline Configuration
  # ===================================================================
  ai:
    ollama:
      # ВАЖНО: При запуске приложения на хост-машине используется `localhost`.
      # Если бы приложение запускалось в Docker в той же сети,
      # нужно было бы использовать имя сервиса: `http://rag-ollama:11434`.
      base-url: http://localhost:11434
      chat:
        options:
          model: llama3 # Модель для генерации текста.
          temperature: 0.7 # "Креативность" модели (0.0 - строго, >1.0 - очень креативно).
          max-tokens: 2048 # Максимальное количество токенов в ответе.
      embedding:
        options:
          # Модель для создания векторных представлений (эмбеддингов).
          model: mxbai-embed-large
    vectorstore:
      pgvector:
        table-name: vector_store # Имя таблицы для хранения векторов.
        index-type: HNSW # Тип индекса для быстрого поиска (Hierarchical Navigable Small World).
        distance-type: COSINE_DISTANCE # Метрика для измерения схожести векторов.
        dimensions: 1024 # Размерность вектора (зависит от embedding-модели).

# ===================================================================
# Observability (Monitoring & Metrics)
# ===================================================================
management:
  endpoints:
    web:
      exposure:
        include: health, info, prometheus, metrics # Эндпоинты, доступные по HTTP.
  endpoint:
    health:
      show-details: when_authorized # Показывать детали для health-чеков.
  metrics:
    tags:
      application: ${spring.application.name} # Глобальный тег для всех метрик.
    distribution:
      # Включить гистограммы для метрики времени ответа HTTP-сервера.
      percentiles-histogram:
        http.server.requests: true
      # Определить "корзины" (SLA) для гистограмм времени ответа.
      sla:
        http.server.requests: 50ms, 100ms, 200ms, 500ms, 1s, 2s

# ===================================================================
# API Documentation (OpenAPI / Swagger)
# ===================================================================
springdoc:
  api-docs:
    path: /api-docs # Путь к JSON-спецификации OpenAPI
  swagger-ui:
    path: /swagger-ui.html # Путь к интерактивной документации Swagger UI
  default-consumes-media-type: application/json
  default-produces-media-type: application/json

# ===================================================================
# Resilience & Fault Tolerance (Resilience4j)
# ===================================================================
resilience4j:
  circuitbreaker:
    instances:
      ollama: # Единственная, правильно названная конфигурация для Ollama
        register-health-indicator: true
        sliding-window-size: 10 # Количество вызовов для анализа.
        minimum-number-of-calls: 3 # Мин. вызовов для срабатывания.
        failure-rate-threshold: 60 # % ошибок для размыкания цепи.
        wait-duration-in-open-state: 15s # Время в "разомкнутом" состоянии.
        record-exceptions: # Считать DataAccessException как сбой
          - org.springframework.dao.DataAccessException
  retry:
    instances:
      ollama:
        max-attempts: 2                  # Макс. количество попыток (1-я + 1 повторная).
        wait-duration: 5s                # Пауза между попытками.
        # Повторять только при явных сетевых ошибках или таймаутах, а не при 5xx ответах.
        retry-on-exception: "org.springframework.web.reactive.function.client.WebClientRequestException, org.springframework.web.client.ResourceAccessException, java.util.concurrent.TimeoutException"
      database: # Новая конфигурация для БД
        max-attempts: 3
        wait-duration: 200ms # Короткая задержка для быстрых операций с БД
        retry-exceptions: # Повторять только при транзиентных ошибках
          - org.springframework.dao.TransientDataAccessException
          - java.util.concurrent.TimeoutException
          - java.sql.SQLTransientException
  timelimiter:
    instances:
      ollama:
        timeout-duration: 120s           # Макс. время ожидания ответа от LLM.
        cancel-running-future: true

# ===================================================================
# Custom Application Properties (app.*)
# ===================================================================
app:
  prompt:
    rag-template-path: "prompts/rag-prompt.tmpl" # Путь к шаблону промпта для RAG
  reranking:
    enabled: true
    keyword-match-boost: 0.1
  rate-limiting:
    enabled: true
    limits:
      - endpoint: "/api/v1/rag/query"
        capacity: 10 # 10 запросов
        refill-period-minutes: 1 # за 1 минуту
      - endpoint: "/api/v1/chat"
        capacity: 20
        refill-period-minutes: 1
  tokenization:
    # "o200k_base" - для Llama 3, Mistral.
    # "cl100k_base" - для моделей OpenAI (GPT-4, GPT-3.5).
    encoding-model: "o200k_base"
  context:
    # Макс. кол-во токенов под контекст. Оставляем запас для системного промпта,
    # вопроса пользователя и генерации ответа. Для Llama-3 (8k) 4k - безопасный лимит.
    max-tokens: 4096
  chat:
    history:
      # Количество последних сообщений для поддержания контекста.
      max-messages: 10
  ingestion:
    scheduler:
      delay-ms: 10000 # 10 секунд между проверками очереди.
    batch-size: 10 # Кол-во документов, обрабатываемых за один раз.
  http-client:
    connect-timeout: 10s # Таймаут на установку TCP-соединения
    response-timeout: 120s # Общий таймаут на получение ответа (включая установку соединения)
    read-write-timeout: 120s # Таймаут на чтение/запись отдельных пакетов данных
  task-executor:
    # Настройки основного пула потоков для @Async задач.
    core-pool-size: 4
    max-pool-size: 16
    queue-capacity: 100
    thread-name-prefix: "app-async-"
  # Настройки для векторного хранилища (pgvector)
  vector-store:
    # Параметры HNSW-индекса для тюнинга производительности и точности.
    # Изменять с осторожностью, требуется профилирование.
    index:
      # Количество соседей на слой графа.
      # Trade-off: выше значение -> лучше точность, медленнее индексация.
      m: 32
      # Глубина поиска при построении индекса.
      # Trade-off: выше значение -> лучше качество индекса, значительно медленнее индексация.
      ef-construction: 128
      # Глубина поиска во время запроса.
      # Trade-off: выше значение -> лучше точность (recall), выше задержка (latency).
      ef-search: 64
  rag:
    # Стратегия поведения, если поиск не нашел документов.
    # "fixed" - вернуть стандартный ответ (быстро, безопасно).
    # "delegate" - (потребует реализации) попросить LLM ответить из общих знаний.
    no-context-strategy: fixed
    # Стратегия упорядочивания документов для контекста.
    # "passthrough" - по релевантности (по умолчанию).
    # "sandwich" - для борьбы с "Lost in the Middle".
    # "recency" - приоритет свежим документам (требует 'timestamp' в метаданных).
    arrangement-strategy: sandwich # Выберите нужную стратегию здесь
    retrieval:
      hybrid:
        vector-search:
          top-k: 5
          similarity-threshold: 0.7
        fts:
          top-k: 10