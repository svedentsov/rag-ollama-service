# Система автономных AI-Агентов для QA

Настоящий проект представляет собой методологическое исследование и исследовательский прототип, реализованный на Spring Boot 3.3+ и Java 21. Целью проекта является изучение и демонстрация интеграции автономных AI-агентов в жизненный цикл разработки и обеспечения качества программного обеспечения (SDLC & QA).

Система использует локально развернутые LLM через Ollama, векторную базу данных `pgvector` для семантического поиска, графовую базу данных `Neo4j` для построения графов знаний и `RabbitMQ` для событийно-ориентированного взаимодействия.

Проект спроектирован как платформа для экспериментов с многоагентными системами, динамическим планированием и применением AI для решения сложных аналитических и стратегических задач в области инженерии ПО.

## Основные концепции

В основе архитектуры лежат несколько ключевых концепций, отличающих этот проект от стандартных RAG-реализаций:

*   **Агент-ориентированная Архитектура:** Система построена на иерархии AI-агентов разного уровня (L2-L5), от простых "инструментов" до "AI-губернаторов", способных принимать стратегические решения. Это позволяет декомпозировать сложные задачи и создавать гибкие, переиспользуемые компоненты.

*   **Динамическая Оркестрация:** В отличие от жестко заданных статических конвейеров, система включает в себя AI-планировщик, который может на лету строить планы выполнения (DAG) из доступных агентов-инструментов для достижения высокоуровневой цели, заданной на естественном языке.

*   **Explainable AI (XAI) & Human-in-the-Loop:** Ключевые компоненты, такие как `QACopilot`, не только выполняют задачи, но и способны объяснять свои действия. Критически важные или "опасные" операции (создание тикетов, запуск CI-задач) требуют явного утверждения человеком через специальный API.

*   **Целостность Базы Знаний (Knowledge Integrity):** Система включает в себя проактивных агентов, которые следят за "здоровьем" базы знаний: находят и предлагают исправить противоречия, а также анализируют пробелы в знаниях на основе запросов пользователей.

## Архитектура системы

### Компоненты высокого уровня

Проект разворачивается с помощью `docker-compose` и включает следующие сервисы:

1.  **`rag-app`**: Основное Spring Boot приложение, реализующее API и логику агентов.
2.  **`postgres`**: PostgreSQL с `pgvector` для хранения векторов и реляционных данных (логов, метрик).
3.  **`ollama`**: Сервис для локального запуска и управления LLM.
4.  **`rabbitmq`**: Брокер сообщений для асинхронного взаимодействия и обработки событий.
5.  **`neo4j`**: Графовая база данных для построения и запросов к Графу Знаний проекта.

### Внутренняя архитектура приложения

Приложение следует принципам Clean Architecture для строгого разделения ответственностей:

*   **Web Layer (`controller`):** Принимает HTTP-запросы, валидирует DTO и делегирует выполнение сервисному слою.
*   **Application Layer (`service`, `orchestration`):** Ядро бизнес-логики. Оркестрирует выполнение статических и динамических конвейеров агентов.
*   **Infrastructure Layer (`repository`, `client`, `tool`):** Реализует взаимодействие с внешними системами: базы данных, Git, Jira, Confluence, LLM.

## Каталог агентов

Система включает в себя широкий набор агентов, сгруппированных по их назначению и уровню в иерархии.

| Уровень | Агент / Конвейер                               | Назначение                                                                                                 |
|:--------|:-----------------------------------------------|:-----------------------------------------------------------------------------------------------------------|
| **L5 (Стратеги)** | **AI CTO / Executive Governor**                | Анализирует здоровье всех проектов в портфеле и формирует стратегический технический роадмап.              |
| | **AI VP of Engineering**                       | Анализирует метрики SDLC (DORA, Git) и предлагает улучшения для инженерных процессов.                        |
| | **AI CFO / ROI Analyst**                         | Анализирует затраты (инфраструктура, LLM, разработка) и рассчитывает ROI для инженерных инициатив.          |
| **L4 (Эксперты)** | **QA Copilot**                                 | Stateful-ассистент, управляющий диалогом и динамическим выполнением задач.                                 |
| | **Root Cause Analyzer**                          | Проводит комплексный анализ первопричины падений тестов, синтезируя данные из логов, diff'ов и отчетов.       |
| | **Test Mentor Bot (XAI)**                        | Выполняет роль AI-наставника, предоставляя детальное код-ревью для автотестов.                             |
| | **Knowledge Consistency Guardian**             | Проверяет базу знаний на внутренние противоречия между различными источниками.                             |
| **L3 (Специалисты)**| **SAST & RBAC Security Agents**                | Выполняют статический анализ кода на предмет уязвимостей (OWASP) и ошибок в конфигурации прав доступа.     |
| | **Test Debt Analyzer**                           | Анализирует историю прогонов для выявления "flaky" и медленных тестов, формируя отчет о техдолге.         |
| | **Performance Predictor**                        | Прогнозирует влияние изменений в коде на производительность (latency, CPU) до слияния в main.              |
| | **Knowledge Gap Advisor**                        | Анализирует запросы без ответа и предлагает темы для новой документации.                                    |
| **L2 (Инструменты)** | **Git Inspector**                              | Извлекает из Git список измененных файлов, diff'ы и историю коммитов.                                    |
| | **Jira/Confluence Fetchers**                   | Извлекают данные из внешних систем для обогащения контекста.                                                |
| | **Code Parser**                                  | Выполняет AST-анализ Java-кода для извлечения его структуры.                                                |
| | **Web Crawler**                                  | Извлекает текстовый контент с внешних веб-страниц для анализа.                                             |

## Стек Технологий

| Категория       | Технология                                | Назначение                                                              |
|:----------------|:------------------------------------------|:------------------------------------------------------------------------|
| **Core**        | Java 21 & Spring Boot 3.3+                | Основной фреймворк и язык.                                              |
| **AI & Agents** | Spring AI, Ollama                         | Интеграция с LLM и векторными хранилищами.                                |
| **Базы Данных** | PostgreSQL + `pgvector`, Neo4j            | Реляционное, векторное и графовое хранилище.                            |
| **События**     | RabbitMQ                                  | Асинхронная обработка событий (веб-хуки, фоновые задачи).                |
| **Надежность**  | Resilience4j                              | Реализация паттернов Circuit Breaker, Retry, TimeLimiter.               |
| **API & Web**   | WebFlux (`WebClient`), MVC (`CompletableFuture`) | Асинхронная обработка HTTP.                                             |
| **Наблюдаемость**| Actuator, Micrometer (Prometheus)         | Мониторинг состояния и сбор метрик.                                     |
| **Тестирование**  | JUnit 5, Mockito, Testcontainers        | Unit- и интеграционное тестирование.                                    |

## Быстрый старт

### Предварительные требования

1.  **Docker и Docker Compose**
2.  **Java 21+ SDK**
3.  **Git**

### Запуск и настройка

1.  **Клонируйте репозиторий:**
    ```bash
    git clone https://github.com/svedentsov/rag-ollama-service.git
    cd rag-ollama-service
    ```

2.  **Запустите всю инфраструктуру:**
    Эта команда соберет образ приложения и запустит все контейнеры.
    ```bash
    docker-compose up --build -d
    ```

3.  **Загрузите LLM-модели в Ollama:**
    ```bash
    # Модель для сбалансированных задач (RAG, чат)
    docker exec -it rag-ollama ollama pull llama3

    # Быстрая модель для классификации и рутинга
    docker exec -it rag-ollama ollama pull phi3

    # Модель для эмбеддингов
    docker exec -it rag-ollama ollama pull mxbai-embed-large
    ```
    *Имена моделей можно изменить в `application.yml`.*

4.  **Проверьте, что сервисы запущены:**
    ```bash
    docker ps
    curl http://localhost:8080/actuator/health
    ```
    Ожидаемый ответ: `{"status":"UP"}`.

## Использование API

Основной точкой входа для интерактивного взаимодействия является **QA Copilot**. Для исследования всех возможностей рекомендуется использовать Swagger UI.

1.  **Откройте Swagger UI в браузере:**
    [http://localhost:8080/swagger-ui.html](http://localhost:8080/swagger-ui.html) (потребуется Basic Auth: `user`/`password`)

2.  **Начните диалог с QA Copilot:**
    -   Используйте эндпоинт `POST /api/v1/copilot/chat`.
    -   Отправьте высокоуровневую задачу:
      ```json
      {
        "message": "Проанализируй изменения между main и feature/new-logic и найди потенциальные риски безопасности."
      }
      ```
    -   Copilot создаст план, выполнит его и вернет вам отчет. В последующих запросах передавайте `sessionId` из ответа для продолжения диалога.