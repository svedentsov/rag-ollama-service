# RAG Service with Spring Boot & Ollama

Этот проект представляет собой микросервис на Spring Boot 3.3+ и Java 21, демонстрирующий реализацию Retrieval-Augmented Generation (RAG) конвейера.

Сервис использует локально развернутые LLM через Ollama и векторную базу данных PostgreSQL с расширением `pgvector`. Проект спроектирован с учетом принципов Clean Architecture и SOLID.

## Ключевые особенности

*   **Clean Architecture:** Разделение на слои (Web, Application, Infrastructure) для повышения тестируемости и поддерживаемости.
*   **Асинхронный конвейер:** Все I/O-операции (запросы к LLM, БД) выполняются неблокирующим способом с использованием `CompletableFuture` и `Project Reactor`.
*   **Потоковая передача (Streaming):** Поддержка Server-Sent Events (SSE) для RAG и чат-эндпоинтов.
*   **Отказоустойчивость:** Применение паттернов надежности (Retry, Circuit Breaker, Timeout) с помощью Resilience4j.
*   **Фоновая обработка:** Асинхронная индексация документов через управляемый пул потоков.
*   **Наблюдаемость (Observability):** Экспорт метрик для Prometheus и health-чеки через Spring Boot Actuator. Сквозная трассировка запросов по `X-Request-ID`.
*   **Тестируемость:** Архитектура, ориентированная на unit- и интеграционное тестирование.

## Архитектура

### Компоненты высокого уровня

Проект оркестрируется с помощью `docker-compose` и состоит из трех основных сервисов:

1.  **`rag-app`**: Spring Boot приложение, реализующее API и бизнес-логику.
2.  **`postgres`**: База данных PostgreSQL с `pgvector` для векторного хранилища.
3.  **`ollama`**: Сервис для локального запуска и управления LLM.

### Внутренняя архитектура приложения

Приложение следует принципам чистой архитектуры для разделения ответственностей:

*   **Web Layer (`controller`):** Отвечает за прием HTTP-запросов, их валидацию и преобразование в DTO. Делегирует выполнение бизнес-логики сервисному слою.
*   **Application Layer (`service`):** Ядро бизнес-логики. Оркестрирует RAG-конвейер, не имея прямых зависимостей от деталей реализации.
*   **Infrastructure Layer (`repository`, `client`):** Содержит реализации для взаимодействия с внешними системами: доступ к базе данных, вызовы к Ollama и т.д.

### RAG-конвейер

Основной RAG-процесс разделен на логические этапы:

`User Query` -> `[Retrieval]` -> `[Augmentation]` -> `[Generation]` -> `User Answer`

1.  **Retrieval (Извлечение):** Поиск релевантных фрагментов (чанков) текста в `pgvector` на основе запроса пользователя.
2.  **Augmentation (Обогащение):** Формирование промпта для LLM из найденных чанков и исходного вопроса.
3.  **Generation (Генерация):** Синтез ответа с помощью LLM (Ollama) на основе сформированного промпта.

## Стек технологий

| Категория          | Технология                                       | Назначение                                                     |
| ------------------ | ------------------------------------------------ | -------------------------------------------------------------- |
| **Core**           | Java 21 & Spring Boot 3.3+                       | Основной фреймворк и язык приложения.                          |
| **AI & RAG**       | Spring AI                                        | Абстракции для интеграции с LLM и векторными хранилищами.      |
|                    | Ollama                                           | Локальный запуск LLM.                                          |
|                    | jtokkit                                          | Подсчет токенов для управления контекстным окном.              |
| **Database**       | PostgreSQL + `pgvector`                          | Векторное и реляционное хранилище.                             |
|                    | Spring Data JPA & Flyway                         | Работа с реляционными данными и управление миграциями схемы БД. |
| **Resilience**     | Resilience4j                                     | Реализация паттернов Circuit Breaker, Retry, TimeLimiter.      |
| **API & Web**      | Spring WebFlux (`WebClient`) & MVC (`CompletableFuture`) | Асинхронная обработка HTTP-запросов и вызовов.                |
|                    | OpenAPI (springdoc)                              | Генерация API-документации.                                    |
| **Observability**  | Actuator & Micrometer (Prometheus)               | Мониторинг состояния приложения и сбор метрик.                 |
| **Testing**        | JUnit 5, Mockito, Testcontainers                 | Unit- и интеграционное тестирование.                           |

## Быстрый старт

### Предварительные требования

1.  **Docker и Docker Compose**
2.  **Java 21+ SDK**
3.  **Git**

### Запуск и настройка

1.  **Клонируйте репозиторий:**
    ```bash
    git clone https://github.com/svedentsov/rag-ollama-service.git
    cd rag-ollama-service
    ```

2.  **Запустите всю инфраструктуру:**
    Эта команда соберет образ приложения и запустит все контейнеры (`postgres`, `ollama`, `rag-app`).
    ```bash
    docker-compose up --build -d
    ```

3.  **Загрузите LLM-модели в Ollama:**
    Откройте новый терминал и выполните команды для загрузки моделей для генерации текста и создания эмбеддингов.
    ```bash
    # Модель для чата
    docker exec -it rag-ollama ollama pull llama3

    # Модель для эмбеддингов
    docker exec -it rag-ollama ollama pull mxbai-embed-large
    ```
    *Имена моделей можно изменить в `application.yml`.*

4.  **Проверьте, что сервисы запущены:**
    ```bash
    # Убедитесь, что все 3 контейнера в статусе "running" или "healthy"
    docker ps

    # Проверьте health-эндпоинт приложения
    curl http://localhost:8080/actuator/health
    ```
    Ожидаемый ответ: `{"status":"UP"}`.

## Использование API

Для взаимодействия с API можно использовать Swagger UI.

1.  **Откройте Swagger UI в браузере:**
    [http://localhost:8080/swagger-ui.html](http://localhost:8080/swagger-ui.html)

2.  **Загрузите документ для RAG:**
    - Используйте эндпоинт `POST /api/v1/documents`.
    - В теле запроса укажите JSON с текстом:
      ```json
      {
        "sourceName": "spring-ai-doc.txt",
        "text": "Spring AI - это проект, целью которого является упрощение разработки приложений, использующих искусственный интеллект."
      }
      ```
    - Вы получите ответ `202 Accepted` с ID задачи, которая будет выполнена в фоне.

3.  **Задайте вопрос с использованием RAG:**
    - Используйте эндпоинт `POST /api/v1/rag/query/stream` для потокового ответа.
    - В теле запроса укажите ваш вопрос:
      ```json
      {
        "query": "Что такое Spring AI?"
      }
      ```
    - Вы получите ответ в виде потока Server-Sent Events.

## Конфигурация

Параметры приложения управляются через файл `src/main/resources/application.yml`. Файл позволяет настраивать:
-   Имена моделей и URL Ollama.
-   Параметры RAG-конвейера.
-   Таймауты и политики Resilience4j.
-   Размеры пулов потоков и параметры кэширования.
-   Настройки rate limiting.

## Тестирование

Проект включает unit-тесты для демонстрации подходов к тестированию.

-   **Запуск тестов:**
    ```bash
    ./gradlew test
    ```

Для интеграционного тестирования рекомендуется использовать Testcontainers.

## Наблюдаемость (Observability)

-   **Метрики для Prometheus:** `GET /actuator/prometheus`.
-   **Состояние приложения:** `GET /actuator/health`.
-   **Трассировка запросов:** Ответы содержат заголовок `X-Request-ID`, который дублируется в логах для отладки.